%==============================================================
\section{Methods}\label{sec:methods}
% Describe the methods and algorithms used, include any formulas. 
% Explain how everything is implemented, and possibly mention the structure of the algorithm. 
% Add demonstrations such as tests, selected runs and validations. 
%==============================================================
Janita, Even writes about GD and SGD?
%------------ Background? -------------------------------------
\subsection{Regression vs. Classification}\label{ssec:regression_classification}


%------------ Gradient Descent --------------------------------
\subsection{Gradient Descent}\label{ssec:gradient_descent}

%% work-in-progress her, m책 samle tankene for 책 forklare dette p책 en god m책te!
For both regression and classification, we want to optimize a set of parameters $\theta$ given a cost function $C(X, \theta)$. This is ususally done by minimizing the cost function. One way of finding the minimum of the cost function given our parameters is by gradient descent (Algorithm \ref{alg:gd}). In gradient descent you start with a random set of parameters, and change these in small steps towards the optimal values by moving iteratively along a gradient \cite{Goodfellow:2016:deep_learning}. The step size is determined by the hyperparameter $\eta$, and is also called the learning rate. The gradient is found by calculating the first derivatives of the cost function with respect to the parameters, and evaluating these for each iteration. The algorithm is run either until some convergence criterion is reached (e.g., gradients approaching 0) it reaches the maximum number of iterations.

While gradient descent effectively minimizes the cost function given the starting parameters, the algorithm can find a local minimum, rather than the lower global minimum. To avoid that the algorithm gets stuck in local minima, it is common to use a small random subset of your data each time you compute the gradients, rather than the full data. This method is known as stochastic gradient descent (Algorithm \ref{alg:sgd}).

\begin{algorithm}
\caption{Gradient descent}\label{alg:gd}
\begin{algorithmic}[1]
    \STATE Initialize parameters $\theta = \theta_0$
    \STATE Choose a learning rate $\eta > 0$
    \REPEAT
        \STATE Compute the gradient $\nabla C(\theta)$
        \STATE Update the parameters: $\theta \leftarrow \theta - \eta \nabla C(\theta)$
    \UNTIL{convergence}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Stochastic gradient descent with mini-batches}\label{alg:sgd}
\begin{algorithmic}[1]
    \STATE Initialize parameters $\theta = \theta_0$
    \STATE Choose a learning rate $\eta > 0$
    \STATE Choose mini-batch size $m$
    \STATE Set number of epochs $K$
    \FOR{epoch $= 1$ to $K$}
        \STATE Shuffle the training data
        \FOR{each mini-batch \( \mathcal{B}_i \) of size $m$}
            \STATE Compute the gradient: $\nabla_{\mathcal{B}_i} C(\theta)$
            \STATE Update the parameters: $\theta \leftarrow \theta - \eta \nabla_{\mathcal{B}_i} C(\theta)$
        \ENDFOR
    \ENDFOR
\end{algorithmic}
\end{algorithm}

%------------ Feed-Forward Neural Network ---------------------
\subsection{Feed-Forward Neural Network}\label{ssec:ffnn}


\begin{figure}[h]
    \centering
    \resizebox{0.9\linewidth}{!}
    {\input{latex/sections/tikz/ffnn}}
    %\includegraphics[width=0.5\linewidth]{}
    \caption{Illustration of a feed forward neural network with one input layer, three hidden layers, and one output layer, where $n$, $m$ and $k$ indicate the number of neurons in the respective layer.}
    \label{fig:enter-label}
\end{figure}


%------------ Logistic Regression -----------------------------
\subsection{Logistic Regression}\label{ssec:logreg}


%------------ Data --------------------------------------------
\subsection{Data}\label{ssec:data}


%------------ Tools -------------------------------------------
\subsection{Tools}\label{ssec:tools}