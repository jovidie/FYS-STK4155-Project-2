%==============================================================
\section{Methods}\label{sec:methods}
% Describe the methods and algorithms used, include any formulas. 
% Explain how everything is implemented, and possibly mention the structure of the algorithm. 
% Add demonstrations such as tests, selected runs and validations. 
%==============================================================
Janita, Even writes about GD and SGD?
%------------ Background? -------------------------------------
\subsection{Regression vs. Classification}\label{ssec:regression_classification}


%------------ Logistic Regression -----------------------------
\subsection{Logistic Regression}\label{ssec:logreg}
Logistic regression is a method of classification, which estimates the probability of being in a certain class. In contrast to linear regression methods, where the outcome is continuous function, the outcome of logistic regression is a linear classifier which gives a decision boundary between classes. This method is often used as a baseline model, particularly in problems in the nature of binary classification, which is what we will focus on.

The sigmoid function is used to fit the model, and is written as
\begin{equation}\label{eq:sigmoid}
    p(z) = \frac{1}{1 + \exp{-z}} , 
\end{equation}
where $z$ is the model's prediction. We define the cost function as the log-likelihood in Equation \eqref{eq:log_likelihood}, which is derived from the Maximum Likelihood Principle.
\begin{equation}\label{eq:log_likelihood}
    \mathcal{C}(\mathbf{\beta}) = - \sum_{i=1}^{n} (y_{i} (\beta_{0} + \beta_{1} x_{i}) - \log (1 + \exp{\beta_{0} + \beta_{1} x_{i}})))
\end{equation}


%------------ Gradient Descent --------------------------------
\subsection{Gradient Descent}\label{ssec:gradient_descent}

%% work-in-progress her, m책 samle tankene for 책 forklare dette p책 en god m책te!
For both regression and classification, we want to optimize a set of parameters $\theta$ given a cost function $C(X, \theta)$. This is ususally done by minimizing the cost function. One way of finding the minimum of the cost function given our parameters is by gradient descent (Algorithm \ref{alg:gd}). In gradient descent you start with a random set of parameters, and change these in small steps towards the optimal values by moving iteratively along a gradient \cite{Goodfellow:2016:deep_learning}. The step size is determined by the hyperparameter $\eta$, and is also called the learning rate. The gradient is found by calculating the first derivatives of the cost function with respect to the parameters, and evaluating these for each iteration. The algorithm is run either until some convergence criterion is reached (e.g., gradients approaching 0) it reaches the maximum number of iterations.

While gradient descent effectively minimizes the cost function given the starting parameters, the algorithm can find a local minimum, rather than the lower global minimum. To avoid that the algorithm gets stuck in local minima, it is common to use a small random subset of your data each time you compute the gradients, rather than the full data. This method is known as stochastic gradient descent (Algorithm \ref{alg:sgd}).

\begin{algorithm}
\caption{Gradient descent}\label{alg:gd}
\begin{algorithmic}[1]
    \STATE Initialize parameters $\theta = \theta_0$
    \STATE Choose a learning rate $\eta > 0$
    \REPEAT
        \STATE Compute the gradient $\nabla C(\theta)$
        \STATE Update the parameters: $\theta \leftarrow \theta - \eta \nabla C(\theta)$
    \UNTIL{convergence}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Stochastic gradient descent with mini-batches}\label{alg:sgd}
\begin{algorithmic}[1]
    \STATE Initialize parameters $\theta = \theta_0$
    \STATE Choose a learning rate $\eta > 0$
    \STATE Choose mini-batch size $m$
    \STATE Set number of epochs $K$
    \FOR{epoch $= 1$ to $K$}
        \STATE Shuffle the training data
        \FOR{each mini-batch \( \mathcal{B}_i \) of size $m$}
            \STATE Compute the gradient: $\nabla_{\mathcal{B}_i} C(\theta)$
            \STATE Update the parameters: $\theta \leftarrow \theta - \eta \nabla_{\mathcal{B}_i} C(\theta)$
        \ENDFOR
    \ENDFOR
\end{algorithmic}
\end{algorithm}

%------------ Feed-Forward Neural Network ---------------------
\subsection{Feed-Forward Neural Network}\label{ssec:ffnn}
In recent years, neural networks have shown promise in solving both regression and classification problems. They and have evolved into several types of networks, with the simplest one called feed-forward neural network (FFNN). In FFNNs, information moves through the layers in one direction, and the network is said to be fully connected if each neuron in a layer is connected to all neurons in the next layer, illustrated in Figure \ref{fig:ffnn}. 

\begin{figure}[h!]
    \centering
    \resizebox{0.9\linewidth}{!}
    {\input{latex/sections/tikz/ffnn}}
    %\includegraphics[width=0.5\linewidth]{}
    \caption{Illustration of a feed-forward neural network with one input layer, three hidden layers, and one output layer, where $n$, $m$ and $k$ indicate the number of neurons in the respective layer.}
    \label{fig:ffnn}
\end{figure}
The architecture of a neural network is often determined by the problem to be solved. According to the universal approximation theorem, a FFNN with a minimum of one input layer, one hidden layer with a non-linear activation function, and one linear output layer, is sufficient to approximate a continuous function \cite[194]{Goodfellow:2016:deep_learning}. 

The output of a hidden layer can be written as 
\begin{equation}\label{eq:ffnn}
    \mathbf{h} = a \Big( \mathbf{W}^{T} \mathbf{x} + \mathbf{b} \Big) ,
\end{equation}
where $a$ is a non-linear activation function, $\mathbf{W}$ is the weight matrix, $\mathbf{x}$ is input, and $\mathbf{b}$ is the bias. 

\subsubsection{Weights and biases}\label{sssec:weights_biases}
The technique used to initialize the weights and biases in the FFNN can be vital for how fast the network learns. For a less ideal method, the network may need more iterations to find an optimal solution. Whereas a clever initialization may reduce the number of iteration needed, as the weight are some of the hyper-parameters that needs tuning. 

\subsubsection{Activation functions}\label{sssec:activation_functions}


\subsubsection{Cost functions}\label{sssec:cost_functions}


\subsubsection{Forward propagation}\label{sssec:forward_propagation}


\subsubsection{Back-propagation}\label{sssec:backpropagation}


%------------ Data --------------------------------------------
\subsection{Data}\label{ssec:data}


%------------ Tools -------------------------------------------
\subsection{Tools}\label{ssec:tools}
The models were implemented in \verb|Python|, and the figures produced using the \verb|matplotlib| library, and stylized using \verb|seaborn|.