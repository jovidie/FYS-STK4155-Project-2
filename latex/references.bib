%================================================================
%------------------------- Books --------------------------------
%================================================================
@book{hastie:2009:elements,
    author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	title = {The {Elements} of {Statistical} {Learning}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	url = {http://link.springer.com/10.1007/978-0-387-84858-7},
	urldate = {2024-09-10},
	publisher = {Springer New York},
	year = {2009},
	doi = {10.1007/978-0-387-84858-7},
}

@book{Goodfellow:2016:deep_learning,
    title   = {Deep Learning},
    author  = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher = {MIT Press},
    url     = {http://www.deeplearningbook.org},
    year    = {2016}
}


@book{raschka:2022:ml_pytorch_scikit,
	title  = {Machine learning with {PyTorch} and {Scikit}-{Learn}: develop machine learning and deep learning models with {Python}},
	author = {Raschka, Sebastian and Liu, Yuxi and Mirjalili, Vahid and Dzhulgakov, Dmytro},
    publisher = {Packt},
	year   = {2022},
}


%================================================================
%------------------------- Articles -----------------------------
%================================================================

@article{wisconsin_example1,
  title={Machine learning in medicine: a practical introduction},
  author={Jenni A. M. Sidey-Gibbons and Chris J. Sidey-Gibbons},
  journal={BMC Medical Research Methodology},
  year={2019},
  volume={19},
  url={https://api.semanticscholar.org/CorpusID:84183143}
}

@article{wisconsin_example2,
  title={A novel feature selection approach for biomedical data classification},
  author={Yonghong Peng and Zhi Qing Wu and Jianmin Jiang},
  journal={Journal of biomedical informatics},
  year={2010},
  volume={43 1},
  pages={
          15-23
        },
  url={https://api.semanticscholar.org/CorpusID:1710466}
}

@inproceedings{wisconsin_example3,
  author={Walter, D. and Mohan, C.K.},
  booktitle={Proceedings of the 2000 Congress on Evolutionary Computation. CEC00 (Cat. No.00TH8512)}, 
  title={ClaDia: a fuzzy classifier system for disease diagnosis}, 
  year={2000},
  volume={2},
  number={},
  pages={1429-1435 vol.2},
  keywords={Fuzzy systems;Diseases;Fuzzy sets;Computer science;Evolutionary computation;Breast cancer;Expert systems;System testing;Machine learning;Humans},
  doi={10.1109/CEC.2000.870821}}

@inproceedings{relu_best_ever,
    title={Rectifier Nonlinearities Improve Neural Network Acoustic Models},
    author={Andrew L. Maas},
    booktitle = {Proceedings of the 30th International Conference on Machine Learning, Vol. 28, 3.},
    year={2013},
    url={https://api.semanticscholar.org/CorpusID:16489696}
}

@inproceedings{first_wisconsin,
  title={Nuclear feature extraction for breast tumor diagnosis},
  author={William Nick Street and William H. Wolberg and Olvi L. Mangasarian},
  booktitle={Electronic imaging},
  year={1993},
  url={https://api.semanticscholar.org/CorpusID:14922543}
}

@article{turing_36,
 ISSN = {00264423, 14602113},
 URL = {http://www.jstor.org/stable/2251299},
 author = {A. M. Turing},
 journal = {Mind},
 number = {236},
 pages = {433--460},
 publisher = {[Oxford University Press, Mind Association]},
 title = {Computing Machinery and Intelligence},
 volume = {59},
 year = {1950}
}

@ARTICLE{mccu_pitt,
  title     = "A logical calculus of the ideas immanent in nervous activity",
  author    = "McCulloch, Warren S and Pitts, Walter",
  abstract  = "Because of the ``all-or-none'' character of nervous activity,
               neural events and the relations among them can be treated by
               means of propositional logic. It is found that the behavior of
               every net can be described in these terms, with the addition of
               more complicated logical means for nets containing circles; and
               that for any logical expression satisfying certain conditions,
               one can find a net behaving in the fashion it describes. It is
               shown that many particular choices among possible
               neurophysiological assumptions are equivalent, in the sense that
               for every net behaving under one assumption, there exists
               another net which behaves under the other and gives the same
               results, although perhaps not in the same time. Various
               applications of the calculus are discussed.",
  journal   = "Bulletin of Mathematical Biophysics",
  publisher = "Springer Science and Business Media LLC",
  volume    =  5,
  number    =  4,
  pages     = "115--133",
  month     =  dec,
  year      =  1943,
  language  = "en"
}

@article{histopath_AI,
  title = {Deep learning in histopathology: the path to the clinic},
  volume = {27},
  ISSN = {1546-170X},
  url = {http://dx.doi.org/10.1038/s41591-021-01343-4},
  DOI = {10.1038/s41591-021-01343-4},
  number = {5},
  journal = {Nature Medicine},
  publisher = {Springer Science and Business Media LLC},
  author = {van der Laak,  Jeroen and Litjens,  Geert and Ciompi,  Francesco},
  year = {2021},
  month = may,
  pages = {775â€“784}
}

@article{battiti1992:newtons_method,
  title = {First- and {{Second-Order Methods}} for {{Learning}}: {{Between Steepest Descent}} and {{Newton}}'s {{Method}}},
  shorttitle = {First- and {{Second-Order Methods}} for {{Learning}}},
  author = {Battiti, Roberto},
  year = {1992},
  month = mar,
  journal = {Neural Computation},
  volume = {4},
  number = {2},
  pages = {141--166},
  issn = {0899-7667},
  doi = {10.1162/neco.1992.4.2.141},
  urldate = {2024-11-01},
  abstract = {On-line first-order backpropagation is sufficiently fast and effective for many large-scale classification problems but for very high precision mappings, batch processing may be the method of choice. This paper reviews first- and second-order optimization methods for learning in feedforward neural networks. The viewpoint is that of optimization: many methods can be cast in the language of optimization techniques, allowing the transfer to neural nets of detailed results about computational complexity and safety procedures to ensure convergence and to avoid numerical problems. The review is not intended to deliver detailed prescriptions for the most appropriate methods in specific applications, but to illustrate the main characteristics of the different methods and their mutual relations.},
  file = {/home/fleskelapp/Zotero/storage/C2DTF6NS/First-and-Second-Order-Methods-for-Learning.html}
}

@article{duchi2011:adagrad,
  title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.},
  author = {Duchi, John and Hazan, Elad and Singer, Yoram},
  year = {2011},
  journal = {Journal of machine learning research},
  volume = {12},
  number = {7},
  urldate = {2024-11-04},
  file = {/home/fleskelapp/Zotero/storage/3STUMG2P/Duchi et al. - 2011 - Adaptive subgradient methods for online learning a.pdf}
}

@misc{hinton2012:rmsprop,
  title = {Neural Networks for Machine Learning Lecture 6a Overview of Mini-Batch Gradient Descent},
  author = {Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  year = {2012},
  address = {Coursera},
  urldate = {2024-11-04},
  file = {/home/fleskelapp/Zotero/storage/Y4WFQKF5/Hinton et al. - 2012 - Neural networks for machine learning lecture 6a ov.pdf}
}

@misc{kingma2017:adam,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1412.6980},
  urldate = {2024-11-04},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/fleskelapp/Zotero/storage/TUGRT8FZ/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/home/fleskelapp/Zotero/storage/C437ZFCS/1412.html}
}

@inproceedings{maclaurin2015:autograd,
  title = {Autograd: {{Effortless}} Gradients in Numpy},
  shorttitle = {Autograd},
  booktitle = {{{ICML}} 2015 {{AutoML}} Workshop},
  author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P.},
  year = {2015},
  volume = {238},
  urldate = {2024-11-04},
  file = {/home/fleskelapp/Zotero/storage/HSGZ3ARH/Maclaurin et al. - 2015 - Autograd Effortless gradients in numpy.pdf}
}

@book{franke1979,
  title = {A Critical Comparison of Some Methods for Interpolation of Scattered Data},
  author = {Franke, Richard},
  year = {1979},
  publisher = {Naval Postgraduate School Monterey, CA},
  file = {C:\Users\Even\Zotero\storage\G88XI5TU\Franke - 1979 - A critical comparison of some methods for interpol.pdf}
}


%================================================================
%------------------------- Web pages ----------------------------
%================================================================

@misc{who_physicians,
	author = {},
	title = {Density of physicians (per 10 000 population)},
	howpublished = {\url{https://data.who.int/indicators/i/CCCEBB2/217795A}},
	year = {},
	note = {[Accessed 05-11-2024]},
}


%================================================================
%------------------------- Misc ---------------------------------
%================================================================

@misc{bc_wisconsin,
  author       = {Wolberg, William, Mangasarian, Olvi, Street, Nick, and Street, W.},
  title        = {{Breast Cancer Wisconsin (Diagnostic)}},
  year         = {1993},
  howpublished = {UCI Machine Learning Repository},
  note         = {{DOI}: https://doi.org/10.24432/C5DW2B}
}

}